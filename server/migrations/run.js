import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import pg from 'pg';
import pool from '../config/database.js';

const { Pool } = pg;

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function runMigrations() {
    let client;
    let migrationPool = pool;

    // Use DIRECT_URL for migrations if available to bypass connection pooling
    if (process.env.DIRECT_URL) {
        console.log('üîó Using Direct Connection for migrations...');
        migrationPool = new Pool({
            connectionString: process.env.DIRECT_URL,
            ssl: process.env.NODE_ENV === 'production' || process.env.DIRECT_URL?.includes('sslmode')
                ? { rejectUnauthorized: false }
                : false
        });
    }

    try {
        client = await migrationPool.connect();
        console.log('üîÑ Running database migrations...');

        // 1. Create migrations table if not exists
        await client.query(`
            CREATE TABLE IF NOT EXISTS _migrations (
                id SERIAL PRIMARY KEY,
                filename VARCHAR(255) UNIQUE NOT NULL,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        `);

        // 2. Get applied migrations
        const { rows: appliedMigrations } = await client.query('SELECT filename FROM _migrations');
        const appliedSet = new Set(appliedMigrations.map(m => m.filename));

        // 3. Get all local migration files
        const files = fs.readdirSync(__dirname)
            .filter(file => file.endsWith('.sql'))
            .sort();

        console.log('Migration directory:', __dirname);
        console.log('Found migration files:', files);

        let migrationCount = 0;

        for (const file of files) {
            if (appliedSet.has(file)) {
                // Skip already applied
                continue;
            }

            console.log(`‚ñ∂Ô∏è Executing migration: ${file}`);
            const filePath = path.join(__dirname, file);
            const sql = fs.readFileSync(filePath, 'utf8');

            // Begin transaction for each migration file
            await client.query('BEGIN');
            try {
                await client.query(sql);
                await client.query('INSERT INTO _migrations (filename) VALUES ($1)', [file]);
                await client.query('COMMIT');
                console.log(`   ‚úÖ Applied: ${file}`);
                migrationCount++;
            } catch (err) {
                await client.query('ROLLBACK');
                console.error(`   ‚ùå Failed to apply ${file}:`, err.message);
                // If the specific error is "duplicate constraint", it likely means the migration ran partially before
                // or without tracking. In this specific recovery case, we can try to mark it as applied if safe,
                // BUT better to just throw so user can fix the state or we handle specific known errors.
                // For "fk_vehicle" specifically which caused the user issue:
                if (err.code === '42710') { // duplicate_object
                    console.log(`   ‚ö†Ô∏è Constraint already exists (duplicate_object). Assuming partial success and marking as done.`);
                    await client.query('INSERT INTO _migrations (filename) VALUES ($1) ON CONFLICT DO NOTHING', [file]);
                } else {
                    throw err;
                }
            }
        }

        if (migrationCount === 0) {
            console.log('‚ú® No new migrations to apply.');
        } else {
            console.log(`‚úÖ Successfully applied ${migrationCount} migrations!`);
        }

        process.exit(0);

    } catch (error) {
        console.error('‚ùå Critical Migration Failure:', error);
        process.exit(1);
    } finally {
        if (client) client.release();
        if (migrationPool !== pool) {
            await migrationPool.end();
            console.log('üîå Migration pool closed.');
        }
    }
}

runMigrations();
